---
layout: post
title: "startup logs 2"
date: 2022-10-17
categories:
---
## logs
We are heading deeper into product development this week.

### Day 182: October 17, 2022
John has gotten Figma code generation from json working for mostly everything. What's left is data labelling for training our model, and figuring out how to actually make the model good. I'm digging deeper into an AI writing tool. Kevin has finished his initial exploration into hosted GPUs and is continuing to read more academic/developer literature on generative AI.

![10-17]({{"/assets/images/10-17-22.JPG" | prepend: site.baseurl }})

*Got new plants*

### Day 183: October 18, 2022
We're continuing to play around with component generation to slowly improve it. Currently, setting properties such as colors is difficult, but creating the components themselves from prompts is possible. The prompts themselves are more component descriptions rather than what humans would actually write, but getting the model working is more important than UI/UX atm, which will come later.

![10-18]({{"/assets/images/10-18-22.jpg" | prepend: site.baseurl }})

*Tae and John playing around with Figma component generation*

### Day 184: Octoboer 19, 2022
We're still working on developing conviction on AI for design. To that end, we are returning back to hypothesis validation. However, we are still spending the bulk of our time on technical exploration.

We have a research channel where we send each other links. I'm going to attach one interesting link every day if people are interested in reading what we read.

This is an interesting [Twitter thread](https://twitter.com/Buntworthy/status/1582307817884889088?s=20&t=-l9Lkw3PQtO73tw2oZ9k2g) that showcases how good people are getting at fine-tuning LLMs.

![10-19]({{"/assets/images/10-19-22.jpg" | prepend: site.baseurl }})

*Evan came down today to SF to visit*

### Day 185: Octoboer 20, 2022
We had a standup today where we defined out plan more concretely. Almost everything about our current idea of building an AI design tool is good except we have a huge question mark about whether or not it will solve a real need for users. This is somewhat ironic because up to this point, our entire ideating process revolved about hypothesis testing/customer discovery. 

Some things we talked about in our meeting:
- The tasks that we need to get done
- Set deadlines for when we need to accomplish tasks by (we have a meeting with our investor, Ali, on October 31st)
- Listed out initial features that we want to build

We are loosely operating under the assumption that all the features that we can think of, we can also build. This is a rather strong assumption, especially because we are working with bleeding edge technology, but it's also a nice moat in the sense that only teams with really strong ML engineers can hope to compete with us. Whether or not we are strong enough at ML engineering will remain a question for the near future, but this is a bet I'm happier to take because it is within our control.

Another interesting [Twitter thread](https://twitter.com/mihail_eric/status/1582768388060741634?s=20&t=NVvzDmLYIQokmtL7KVNF1w) on what people are doing to work with LLMs (specifically prompt engineering). Definitely something that my team and I are looking at to improve how we work with our LLMs. 

![10-20]({{"/assets/images/10-20-22.jpg" | prepend: site.baseurl }})
*Bought a new HHKB keyboard so my typing in the work area isn't as loud lol*